//Big O for Exercise 1
//A) Find person from 15 people that owns a dog of a particular breed by shouting out to the room: 
        //I would say O(n^2) because you're looking through a set of people and then determining if 1. they're a willing participant & 2. if they have a golden retriever
        //If the data for a scenario like that gets larger, it would grow polynomially because you're generally searching for an answer that meets two qualifiers that are equally 
        //vital to answering the question
//(B) Find person from 15 people that owns a golden by asking each person one at a time:
        //I would say O(2n) because you're basically looping through each person asking the same singular question until you find an answer.
        //If the amount of data would grow, it the time complexity would grow linearly because you would basically go at the same pace to look for an answer
        //but the metaphorical hill would go steadily steeper.

function isEven(value) { //Exercise Two
    if (value % 2 == 0) { 
        return true; //constant
    }
    else {
        return false; //constant
    }
}; //This would be a O(1) because even if I enter 1,000,000 or 1 the returning data would either be true or false, 

function areYouHere(arr1, arr2) { //Excercise 3
    for (let i = 0; i < arr1.length; i++) { //linear
        const el1 = arr1[i]; //constant
        for (let j = 0; j < arr2.length; j++) { //polynomial
            const el2 = arr2[j]; //constant
            if (el1 === el2) return true; //constant
        }
    }
    return false;//constant
} //This algorithm would be O(n^k) because the more arr1 and arr2 grow it will quickly take much longer to find if the arrays have elements in common

function doubleArrayValues(array) { //Excercise 4
    for (let i = 0; i < array.length; i++) { //linear
        array[i] *= 2;
    }
    return array;
}  //This algorithm would be O(n) because the more lenghty the array gets, the function keeps the same pace to look at the data, but the time it takes slowly increases

function naiveSearch(array, item) { //Exercise 5
    for (let i = 0; i < array.length; i++) { //linear
        if (array[i] === item) { //linear
            return i; //constant
        }
    }
} //This algorithm would be O(n) because the more lenghty the array gets, the function keeps the same pace to look at the data in it, but the rate of comparison stays the same i.e. the item

function createPairs(arr) { //Exercise 6
    for (let i = 0; i < arr.length; i++) { // loop 1
        for(let j = i + 1; j < arr.length; j++) { //polynomial loop 2, depends on loop 1 to execute
            console.log(arr[i] + ", " +  arr[j] ); //constant
        }
    }
} //This algorithm would be O(n^k) because when the amount of data grows the more and more amounts of pairs it has to generate, and since loop 2 depends on loop 1 executing it's basically 
//got to hold on to i in order to find j

function compute(num) { //Exercise 7
    let result = [];
    for (let i = 1; i <= num; i++) {

        if (i === 1) {
            result.push(0);
        }
        else if (i == 2) {
            result.push(1);
        }
        else {
            result.push(result[i - 2] + result[i - 3]);
        }
    }
    return result;
} //This function generates an array, its length is dictated by the number sent in as an argument, the values in the array follow the Fibonnaci sequence starting from zero and going until the desrired legnth is reached.
//The Big O for this function would be O(n) because the output generated by the input increases only by the num sent in

console.log(compute(10))


